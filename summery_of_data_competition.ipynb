{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 数据探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voting\n",
    "Voting（投票机制）分为硬投票和软投票两种，其原理采用少数服从多数的思想，此方法可用于分类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 软投票示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入相关包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.data import iris_data\n",
    "from mlxtend.plotting import plot_decision_regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EnsembleVoteClassifier实现**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Initializing Classifiers\n",
    "    clf1 = LogisticRegression(random_state=0, solver='lbfgs', multi_class='auto')\n",
    "    clf2 = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "    clf3 = SVC(random_state=0, probability=True, gamma='auto')\n",
    "    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[2, 1, 1], voting='soft')\n",
    "\n",
    "    # Loading some example data\n",
    "    X, y = iris_data()\n",
    "    X = X[:, [0, 2]]\n",
    "\n",
    "    # plotting decision regions\n",
    "    gs = gridspec.GridSpec(1, 4)\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    \n",
    "    # 可视化分类边界\n",
    "    for clf, lab, grd, in zip([clf1, clf2, clf3, eclf],\n",
    "                              ['Logistic Regression', 'Random Forest', 'RBF kernel SVM', 'Ensemble'],\n",
    "                              itertools.product([0, 1], repeat=2)):\n",
    "        clf.fit(X, y)\n",
    "        ax = plt.subplot(gs[0, grd[0] * 2 + grd[1]])\n",
    "        fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "        plt.title(lab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Bagging算法  \n",
    "Bagging算法，又称装袋算法，是机器学习领域的一种集成学习算法。最初由Leo Breiman于1994年提出。之所以被称为装袋法，是因为它采用了一种有放回的抽样方法来生成训练数据。通过多轮有放回的对初始训练集进行随机采样，多个训练集被并行化生成，对应可训练出多个基学习器（基学习器间不存在强依赖关系），再将这些基学习器结合，构建出强学习器。其本质是引入了样本扰动，通过增加样本随机性，达到降低方差的效果。\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"./img/9210113-8ae1f9ba634caf4f.png\" width=\"600\" hegiht=\"\" ></center>\n",
    "<center><br>bagging流程图</br></center>\n",
    "<br></br>\n",
    "\n",
    "因为 bagging 方法可以减小过拟合，所以通常在强分类器和复杂模型上使用时表现的很好（例如，完全生长的决策树，fully developed decision trees），相比之下 boosting 方法则在弱模型上表现更好（例如，浅层决策树，shallow decision trees）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 执行步骤\n",
    "假设有1000个样本，70%的样本作为训练集，30%的样本作为测试集。\n",
    "- STEP1：从训练集700条里样本随机抽出500条样本，用来训练，于是生成了一个基学习器。\n",
    "- STEP2：然后有放回的再从700条样本在随机抽出500条样本，用来训练，于是又生成了一个基学习器\n",
    "- STEP3：假设以步骤2的方式随机抽取100次，这样就生成了100个基学习器了\n",
    "- STEP4：用这100个基学习器对测试集的每一个样本都进行测试，然后通过投票的方式决定测集样本的预测结果。如果一个样本被这100个基学习器投票，即预测分类，被分为1的票数有80票，被分为0的有20票，显然，这个样本的预测结果为1。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 使用sklearn库实现Bagging方法\n",
    "**BaggingClassifier**  \n",
    "决策树是一个可读性很强、分类快，同时不需要对数据进行归一化还有缩放的处理。但是决策树有个不足的地方就是非常容易过拟合，所以必须要采取一些方法进行剪枝。而bagging方法的出现，可以完美地解决了决策树过拟合的问题，同时bagging的使用也会使分类器分类效果得到了显著的提高。  \n",
    "在 scikit-learn 中，bagging 方法使用统一的 BaggingClassifier 元估计器."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入相关包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**载入iris数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# print('feature=',X)\n",
    "# print('target=',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bagging融合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BaggingMethod(X, y):\n",
    "    '''\n",
    "    Bagging方法实现分类\n",
    "    INPUT -> 特征, 分类标签\n",
    "    '''\n",
    "    scaler = StandardScaler() # 标准化转换\n",
    "    scaler.fit(X)  # 训练标准化对象\n",
    "    traffic_feature= scaler.transform(X)   # 转换数据集\n",
    "    feature_train, feature_test, target_train, target_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    tree = DecisionTreeClassifier(criterion='entropy', max_depth=None)\n",
    "\n",
    "    clf = BaggingClassifier(base_estimator=tree, \n",
    "                            n_estimators=500,   # 生成500个决策树\n",
    "                            max_samples=1.0,\n",
    "                            max_features=1.0,\n",
    "                            bootstrap=True,\n",
    "                            bootstrap_features=False,\n",
    "                            n_jobs=1,\n",
    "                            random_state=1)\n",
    "    clf.fit(feature_train, target_train)\n",
    "\n",
    "    # 模型测试\n",
    "    predict_results = clf.predict(feature_test)\n",
    "    print(accuracy_score(predict_results, target_test))\n",
    "    conf_mat = confusion_matrix(target_test, predict_results)\n",
    "    print(conf_mat)\n",
    "    print(classification_report(target_test, predict_results))\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**主程序**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "**参数说明：**\n",
    "\n",
    "1. base_estimator：基本模型，None默认为决策树；\n",
    "2. n_estimators=500：生成500个决策；\n",
    "3. max_samples : int或float，可选（默认值= 1.0），从X抽取以训练每个基本模型（estimator）的样本数，如果为int，则抽取样本 max_samples，如果float，则抽取本 max_samples * X.shape[0]。\n",
    "4. max_features：int或float，可选（默认值= 1.0）从X绘制以训练每个基本估计量的要素数量。如果为int，则绘制特征 max_features。如果是浮动的，则绘制特征 max_features * X.shape[1]。\n",
    "5. bootstrap : 布尔值，可选（默认= True）是否抽取样本进行替换。如果为False，则执行不替换的采样。\n",
    "6. n_jobs : int或None（可选）（默认为None）fit和 并行运行的作业数predict。None除非joblib.parallel_backend上下文中，否则表示1 。-1表示使用所有处理器。\n",
    "7. random_state : 整型，RandomState实例或无，可选（默认值：无）如果为int，则random_state是随机数生成器使用的种子；否则为false。\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = BaggingMethod(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 参考资料\n",
    "1. 机器学习中的集成方法（2）--Bagging（装袋法）（https://www.jianshu.com/p/fa212d4391f7）;\n",
    "2. scikit-learn中BaggingClassifier参数（https://blog.csdn.net/Asdas_/article/details/104055529）；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
